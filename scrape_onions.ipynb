{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(month, year):\n",
    "    \"\"\"This function will accept the month and year as arguments\n",
    "       and return the data for that particular month\n",
    "       Args:\n",
    "           month: string containing the name of the month\n",
    "           year:  string containing the year\n",
    "       Return:\n",
    "           month_df: dataframe for the given month\n",
    "    \"\"\"\n",
    "    # create dataframe to store the scrapped data\n",
    "    month_df = pd.DataFrame()\n",
    "    \n",
    "    # check the month to decide the number of days\n",
    "    if month in ['Jan', 'Mar', 'May', 'Jul', 'Aug', 'Oct', 'Dec']:\n",
    "        last_date = 31\n",
    "    elif month in ['Apr', 'Jun', 'Sep', 'Nov']:\n",
    "        last_date = 30 \n",
    "    elif month == 'Feb' and int(year) % 4 == 0:\n",
    "        last_date = 29\n",
    "    else:\n",
    "        last_date = 28\n",
    "    \n",
    "    # iterate over each day in the month\n",
    "    for i in range(1, last_date + 1):\n",
    "        if i < 10:\n",
    "            # construct the date \n",
    "            date = '0' + str(i) + '-' + month + '-' + year\n",
    "        else:\n",
    "            date = str(i) + '-' + month + '-' + year\n",
    "         \n",
    "        # create url\n",
    "        url = 'https://agmarknet.gov.in/SearchCmmMkt.aspx?Tx_Commodity=23&Tx_State=UP&Tx_District=0&Tx_Market=0&DateFrom={}&DateTo={}&Fr_Date={}&To_Date={}&Tx_Trend=2&Tx_CommodityHead=Onion&Tx_StateHead=Uttar+Pradesh&Tx_DistrictHead=--Select--&Tx_MarketHead=--Select--'.format(date, date, date, date)\n",
    "        \n",
    "        # get the request from the url\n",
    "        r = requests.get(url)\n",
    "        \n",
    "        # create soup object\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "        try:\n",
    "            # extract the data for the day\n",
    "            df = pd.read_html(str(soup.find_all('table')))[0][:-2]\n",
    "            # concatenate each day data with the month dataframe\n",
    "            month_df = pd.concat([month_df, df], axis = 0)    \n",
    "        except:\n",
    "            print('No data available for {}'.format(date))\n",
    "            \n",
    "    print('Data scrapping done for month {} and year {}'.format(month, year))      \n",
    "    \n",
    "    return month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the list of the months \n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# iterate over the years\n",
    "for year in range(2002, 2021):\n",
    "    # iterate over the months\n",
    "    for month in months:\n",
    "        # get the dataframe\n",
    "        df = get_data(month, str(year))\n",
    "        # construct the file name\n",
    "        file_name = month + '_' + str(year)[-2:] + '.csv'\n",
    "        # save the data as a csv file\n",
    "        df.to_csv(file_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug_02.csv\n",
      "Jul_02.csv\n",
      "Jun_02.csv\n",
      "Nov_02.csv\n",
      "Oct_02.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in os.listdir('Onion_Data'):\n",
    "    if file.split('.')[0][-2:] == '02':\n",
    "        print(file)\n",
    "        month_df = pd.read_csv(os.path.join('Onion_Data', file))\n",
    "        df = pd.concat([df, month_df], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_2002.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Name</th>\n",
       "      <th>District Name</th>\n",
       "      <th>Market Name</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Group</th>\n",
       "      <th>Arrivals (Tonnes)</th>\n",
       "      <th>Min Price (Rs./Quintal)</th>\n",
       "      <th>Max Price (Rs./Quintal)</th>\n",
       "      <th>Modal Price (Rs./Quintal)</th>\n",
       "      <th>Reported Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Varanasi(Grain)</td>\n",
       "      <td>Nasik</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>460</td>\n",
       "      <td>510</td>\n",
       "      <td>480</td>\n",
       "      <td>02 Aug 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Varanasi(Grain)</td>\n",
       "      <td>Nasik</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>465</td>\n",
       "      <td>510</td>\n",
       "      <td>490</td>\n",
       "      <td>03 Aug 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Varanasi(Grain)</td>\n",
       "      <td>Nasik</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>475</td>\n",
       "      <td>510</td>\n",
       "      <td>500</td>\n",
       "      <td>05 Aug 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Varanasi</td>\n",
       "      <td>Varanasi(Grain)</td>\n",
       "      <td>Nasik</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>490</td>\n",
       "      <td>520</td>\n",
       "      <td>510</td>\n",
       "      <td>07 Aug 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Ghaziabad</td>\n",
       "      <td>Ghaziabad</td>\n",
       "      <td>Red</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>10.0</td>\n",
       "      <td>380</td>\n",
       "      <td>450</td>\n",
       "      <td>420</td>\n",
       "      <td>08 Aug 2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      State Name District Name      Market Name Variety       Group  \\\n",
       "0  Uttar Pradesh      Varanasi  Varanasi(Grain)   Nasik  Vegetables   \n",
       "1  Uttar Pradesh      Varanasi  Varanasi(Grain)   Nasik  Vegetables   \n",
       "2  Uttar Pradesh      Varanasi  Varanasi(Grain)   Nasik  Vegetables   \n",
       "3  Uttar Pradesh      Varanasi  Varanasi(Grain)   Nasik  Vegetables   \n",
       "4  Uttar Pradesh     Ghaziabad        Ghaziabad     Red  Vegetables   \n",
       "\n",
       "   Arrivals (Tonnes)  Min Price (Rs./Quintal)  Max Price (Rs./Quintal)  \\\n",
       "0             3700.0                      460                      510   \n",
       "1             3000.0                      465                      510   \n",
       "2             2200.0                      475                      510   \n",
       "3             2500.0                      490                      520   \n",
       "4               10.0                      380                      450   \n",
       "\n",
       "   Modal Price (Rs./Quintal) Reported Date  \n",
       "0                        480   02 Aug 2002  \n",
       "1                        490   03 Aug 2002  \n",
       "2                        500   05 Aug 2002  \n",
       "3                        510   07 Aug 2002  \n",
       "4                        420   08 Aug 2002  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(386, 10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # to get image from the web\n",
    "import shutil # to save it locally\n",
    "\n",
    "## Set up the image URL and filename\n",
    "image_url = \"https://cdn.pixabay.com/photo/2020/02/06/09/39/summer-4823612_960_720.jpg\"\n",
    "filename = image_url.split(\"/\")[-1]\n",
    "\n",
    "# Open the url image, set stream to True, this will return the stream content.\n",
    "r = requests.get(image_url, stream = True)\n",
    "\n",
    "# Check if the image was retrieved successfully\n",
    "if r.status_code == 200:\n",
    "    # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "    r.raw.decode_content = True\n",
    "    \n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "    with open(filename,'wb') as f:\n",
    "        shutil.copyfileobj(r.raw, f)\n",
    "        \n",
    "    print('Image sucessfully Downloaded: ',filename)\n",
    "else:\n",
    "    print('Image Couldn\\'t be retreived')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib2\n",
    "import os\n",
    "import cookielib\n",
    "import json\n",
    "\n",
    "def get_soup(url,header):\n",
    "    return BeautifulSoup(urllib2.urlopen(urllib2.Request(url,headers=header)),'html.parser')\n",
    "\n",
    "\n",
    "query = raw_input(\"query image\")# you can change the query for the image  here\n",
    "image_type=\"ActiOn\"\n",
    "query= query.split()\n",
    "query='+'.join(query)\n",
    "url=\"https://www.google.co.in/search?q=\"+query+\"&source=lnms&tbm=isch\"\n",
    "print url\n",
    "#add the directory for your image here\n",
    "DIR=\"Pictures\"\n",
    "header={'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"\n",
    "}\n",
    "soup = get_soup(url,header)\n",
    "\n",
    "\n",
    "ActualImages=[]# contains the link for Large original images, type of  image\n",
    "for a in soup.find_all(\"div\",{\"class\":\"rg_meta\"}):\n",
    "    link , Type =json.loads(a.text)[\"ou\"]  ,json.loads(a.text)[\"ity\"]\n",
    "    ActualImages.append((link,Type))\n",
    "\n",
    "print  \"there are total\" , len(ActualImages),\"images\"\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "            os.mkdir(DIR)\n",
    "DIR = os.path.join(DIR, query.split()[0])\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "            os.mkdir(DIR)\n",
    "###print images\n",
    "for i , (img , Type) in enumerate( ActualImages):\n",
    "    try:\n",
    "        req = urllib2.Request(img, headers={'User-Agent' : header})\n",
    "        raw_img = urllib2.urlopen(req).read()\n",
    "\n",
    "        cntr = len([i for i in os.listdir(DIR) if image_type in i]) + 1\n",
    "        print cntr\n",
    "        if len(Type)==0:\n",
    "            f = open(os.path.join(DIR , image_type + \"_\"+ str(cntr)+\".jpg\"), 'wb')\n",
    "        else :\n",
    "            f = open(os.path.join(DIR , image_type + \"_\"+ str(cntr)+\".\"+Type), 'wb')\n",
    "\n",
    "\n",
    "        f.write(raw_img)\n",
    "        f.close()\n",
    "    except Exception as e:\n",
    "        print \"could not load : \"+img\n",
    "        print e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
